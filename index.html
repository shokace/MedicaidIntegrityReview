<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Medicaid Data Integrity Review</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Chivo:wght@400;700;900&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="styles.css?v=4" />
  </head>
  <body>
    <div class="noise"></div>
    <header class="hero">
      <p class="eyebrow">Medicaid Provider Spending, Jan 2018 - Dec 2024</p>
      <h1>Medicaid Data Integrity Review</h1>
      <p class="subtitle">
        This site is a forensic quality check on a very large Medicaid spending table. We are not making legal allegations against people or organizations.
        We are testing whether the numbers themselves look like they came from a real production system, versus being heavily edited, partially synthesized,
        or transformed in ways that changed their natural statistical structure.
      </p>
      <div class="hero-grid">
        <div class="card stat">
          <span>Rows analyzed</span>
          <strong id="rowsAnalyzed">-</strong>
        </div>
        <div class="card stat">
          <span>Duplicate key rate</span>
          <strong id="dupRate">-</strong>
        </div>
        <div class="card stat">
          <span>Final rule verdict</span>
          <strong id="verdictLabel">-</strong>
        </div>
      </div>
    </header>

    <main>
      <section class="panel" id="read-this-first">
        <h2>Read This First</h2>
        <p>
          We follow a strict ordered workflow with six statistical checks grouped into five independent signal families. The order matters because early checks give context for later checks.
          A single failed signal is not enough. Some failure is expected in real healthcare data because billing systems are complicated. The decision rule here is:
          if <strong>3 or more independent signal families fail</strong>, the dataset is flagged as <strong>likely synthetic or altered</strong> at the dataset level.
        </p>
        <p>
          This is a <strong>screening framework</strong>. It detects dataset-level transformation and aggregation artifacts. It is not a row-level fraud detector,
          not a billing-abuse detector, and not legal proof of illegal activity.
        </p>
      </section>

      <section class="panel" id="plain-language-definitions">
        <h2>Plain-Language Definitions</h2>
        <div class="grid-2">
          <div class="card prose-block">
            <h3>What is a "ratio"?</h3>
            <p>
              A ratio is one number divided by another. Here, a key ratio is <code>TOTAL_PAID / TOTAL_CLAIMS</code>, which acts like an implied payment per claim.
              If this jumps around too wildly in places where behavior should be more stable, it can indicate inconsistent data generation.
            </p>
            <h3>What is "correlation"?</h3>
            <p>
              Correlation is a number from -1 to +1 that tells us how strongly two variables move together. Closer to +1 means strong positive relationship.
              In billing aggregates, some relationships should usually be reasonably strong. If they are unexpectedly weak, structure may have been disrupted.
            </p>
            <h3>What is "entropy"?</h3>
            <p>
              Entropy is a measure of randomness or variety. High entropy means values are spread out; low entropy means values repeat too much.
              Repetition beyond what the process should produce can be a sign of templating, copy-paste behavior, or synthetic generation.
            </p>
          </div>
          <div class="card prose-block">
            <h3>What is "temporal noise"?</h3>
            <p>
              Temporal means over time. Noise is natural month-to-month irregularity. Real systems are usually messy. If a long time series is too smooth,
              it can mean someone generated numbers to look clean rather than capturing real operational variation.
            </p>
            <h3>What is "heaping"?</h3>
            <p>
              Heaping means values cluster on specific payment-grid steps (for example, cents ending on 00, 25, 50, 75).
              In healthcare reimbursement, some heaping is expected, but extreme concentration can indicate transformation artifacts.
            </p>
            <h3>What does "fail" mean here?</h3>
            <p>
              Fail means the metric crossed a pre-set threshold in a way that is unusual under this methodology. It does not mean guilt.
              It means the dataset deserves extra validation before high-stakes decisions are made.
            </p>
            <h3>Why healthcare can look irregular</h3>
            <p>
              Healthcare payment is heavily rule-driven: HCPCS/CPT fee schedules, RVU conversion, negotiated reimbursement grids, and shared beneficiaries across providers.
              These operational mechanics can produce artifacts in aggregated data even when no row-level fabrication exists.
            </p>
          </div>
        </div>
      </section>

      <section class="panel" id="state-view">
        <h2>State Lens</h2>
        <p>
          National totals can mask localized structure. Select a state to rerun the same interpretation on that state slice. All cards, charts, tables, and verdicts below update.
        </p>
        <div class="state-controls">
          <label for="stateSelect">Selected geography</label>
          <select id="stateSelect"></select>
          <p id="stateSelectionNote">State: ALL</p>
        </div>
        <div id="usMap" class="us-map" aria-label="Interactive United States map"></div>
        <div class="card state-outliers-card">
          <h3>Provider Peer-Group Outlier Ranking</h3>
          <p id="peerOutlierSummary">
            Providers are ranked by peer-relative outlier score within the selected geography. This is a screening signal, not legal proof.
          </p>
          <table>
            <thead>
              <tr>
                <th>Rank</th>
                <th>Provider NPI</th>
                <th>State</th>
                <th>Risk</th>
                <th>Outlier Score</th>
                <th>Rows >= 3 sigma</th>
                <th>Peer Cells</th>
                <th>Total Claims</th>
                <th>Total Paid</th>
              </tr>
            </thead>
            <tbody id="peerOutlierTable"></tbody>
          </table>
        </div>
      </section>

      <section class="panel" id="scorecard">
        <h2>Signal Scorecard (Ordered Workflow)</h2>
        <p>
          Compact summary of pass/fail by signal. Full interpretation and thresholds are in each Signal 1-6 detail section below.
        </p>
        <div class="card score-summary">
          <p><strong>Decision Rule:</strong> <span id="ruleText">-</span></p>
          <p><strong>Failed Independent Families:</strong> <span id="failCount">-</span></p>
          <p><strong>Verdict:</strong> <span id="verdictText">-</span></p>
        </div>
        <div id="signalCards" class="signal-grid"></div>
      </section>

      <section class="panel" id="data-health">
        <h2>Data Health and Baseline Integrity</h2>
        <p>
          Before anomaly scoring, we verify basic integrity conditions. If these are broken, downstream forensics can produce misleading conclusions.
          This section shows structural checks, suppression consistency, and missingness profile so the rest of the interpretation is anchored in data quality context.
        </p>
        <div class="grid-2">
          <div class="card">
            <h3>Integrity Checks</h3>
            <ul id="healthChecks"></ul>
          </div>
          <div class="card">
            <h3>Missingness by Column</h3>
            <table>
              <thead><tr><th>Column</th><th>Missing %</th></tr></thead>
              <tbody id="missingnessTable"></tbody>
            </table>
          </div>
        </div>
      </section>

      <section class="panel" id="payment-mechanics">
        <h2>Signal 1 Detail: Reimbursement Ratio Clustering</h2>
        <p>
          We group records by HCPCS procedure code and evaluate variability in implied unit payment. The coefficient of variation (CV) tells us how large
          the spread is relative to the average. Extremely high CV across heavily used codes can indicate a mixture of incompatible regimes, value injection,
          transformation artifacts, or data generation inconsistencies.
        </p>
        <div class="card">
          <h3>Top Suspicious HCPCS (from computed table)</h3>
          <table>
            <thead><tr><th>HCPCS</th><th>Claims</th><th>CV</th><th>Score</th></tr></thead>
            <tbody id="hcpcsTable"></tbody>
          </table>
        </div>
        <div class="card" id="signal1Box">
          <h3>Signal 1 Result</h3>
          <p id="signal1Status">-</p>
          <p id="signal1Explain">-</p>
          <ul id="signal1Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="digit-forensics">
        <h2>Signal 2 Detail: Last Digit Analysis</h2>
        <p>
          We inspect the final cents digit (0-9) of implied unit payment (<code>TOTAL_PAID / TOTAL_CLAIMS</code>). Human editing and scripted generation often create unnatural endpoint preferences.
          For example, too many values ending in specific digits can be a warning sign. This check compares observed digit shares to a simple reference pattern.
        </p>
        <div class="card">
          <h3>Cents Last-Digit Distribution</h3>
          <canvas id="digitChart" width="920" height="280" aria-label="digit chart"></canvas>
        </div>
        <div class="card" id="signal2Box">
          <h3>Signal 2 Result</h3>
          <p id="signal2Status">-</p>
          <p id="signal2Explain">-</p>
          <ul id="signal2Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="relationships">
        <h2>Signal 3 Detail: Correlation Structure</h2>
        <p>
          Some fields should track each other because they come from the same operational process. Weak linkage in key pairs can imply that parts of the dataset
          were generated under different assumptions or modified independently.
        </p>
        <div class="card">
          <h3>Core Correlations</h3>
          <table>
            <thead><tr><th>Pair</th><th>Correlation</th></tr></thead>
            <tbody id="corrTable"></tbody>
          </table>
        </div>
        <div class="card" id="signal3Box">
          <h3>Signal 3 Result</h3>
          <p id="signal3Status">-</p>
          <p id="signal3Explain">-</p>
          <ul id="signal3Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="time-series">
        <h2>Signal 4 Detail: Temporal Noise</h2>
        <p>
          We test month-level behavior for unrealistic smoothness. Natural operational data usually has shocks, seasonal pulses, and uneven swings.
          Extremely smooth movement can be suspicious; moderate variability is often expected in real-world systems.
        </p>
        <div class="card">
          <h3>Monthly Volatility (Delta Standard Deviation)</h3>
          <canvas id="volChart" width="920" height="280" aria-label="volatility chart"></canvas>
        </div>
        <div class="card" id="signal4Box">
          <h3>Signal 4 Result</h3>
          <p id="signal4Status">-</p>
          <p id="signal4Explain">-</p>
          <ul id="signal4Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="entropy-detail">
        <h2>Signal 5 Detail: Entropy</h2>
        <p>
          Entropy measures how much variety exists in implied unit-payment endings. We use last-two-cent endings as a compact fingerprint. If diversity is too low,
          it can suggest templating, repetition, or generated values instead of natural operational variation.
        </p>
        <div class="card" id="signal5Box">
          <h3>Entropy Result</h3>
          <p id="signal5Status">-</p>
          <p id="signal5Explain">-</p>
          <ul id="signal5Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="heaping-detail">
        <h2>Signal 6 Detail: Heaping Detection (Grid Spacing)</h2>
        <p>
          This signal measures how strongly implied unit-payment cents cluster on reimbursement-grid spacing.
          Some heaping is operationally normal in healthcare pricing. The objective is to detect unusually strong concentration that can suggest transformation artifacts.
        </p>
        <div class="card" id="signal6Box">
          <h3>Heaping Result</h3>
          <p id="signal6Status">-</p>
          <p id="signal6Explain">-</p>
          <ul id="signal6Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="methodology">
        <h2>Methodology and Interpretation Notes</h2>
        <ol>
          <li>Compute standardized outputs from the parquet source file into JSON and CSV artifacts.</li>
          <li>Apply six checks in fixed order, with thresholds calibrated from a null-model baseline.</li>
          <li>Treat Last Digit and Entropy as one structural family because both probe the same discretization phenomenon.</li>
          <li>Group checks into independent signal families and apply the rule: 3 or more failed families triggers a dataset-level warning state.</li>
          <li>Interpret results in payer-mechanics context (fee schedules, RVU factors, reimbursement grids, shared beneficiaries).</li>
          <li>Use this as an integrity triage tool and follow with deeper domain review, not as standalone legal proof.</li>
          <li>Calibrate thresholds with null-model simulation benchmarking (realistic payer-process bootstraps versus artifacted synthetic generators).</li>
        </ol>
      </section>

      <section class="panel" id="payer-mechanics">
        <h2>Payer Mechanics Context</h2>
        <p>
          Correlation weakness in aggregated healthcare data can reflect payment-system design, not fabrication. These mechanics matter when interpreting signal failures:
        </p>
        <div class="grid-2">
          <div class="card prose-block">
            <h3>CPT/HCPCS Fee Schedules</h3>
            <p>
              Many services are paid from predefined code-level schedules. This can create repeated reimbursement patterns and non-uniform value spacing in aggregates.
            </p>
            <h3>RVU Conversion Factors</h3>
            <p>
              Payments may be derived from RVU formulas and conversion factors. Small policy changes can shift amounts systematically across many claims at once.
            </p>
          </div>
          <div class="card prose-block">
            <h3>Negotiated Reimbursement Grids</h3>
            <p>
              Contracted rates are often stepped or banded by code/category and payer. This can produce heaping and cluster effects that are operational, not synthetic.
            </p>
            <h3>Shared Beneficiaries Across Providers</h3>
            <p>
              The same beneficiaries may appear across multiple providers and services. In rolled-up data, this can blur expected pairwise correlations without implying fabrication.
            </p>
          </div>
        </div>
      </section>

      <section class="panel" id="appendix">
        <h2>Appendix and Artifacts</h2>
        <p>
          Main machine outputs consumed by this page:
          <code>outputs/json/report_by_state.json</code>,
          <code>outputs/json/signal_score_by_state.json</code>,
          <code>outputs/json/provider_peer_outliers_by_state.json</code>,
          with fallback to <code>outputs/json/report.json</code> and <code>outputs/json/signal_score.json</code>,
          <code>outputs/tables/unit_price_top_suspicious_hcpcs.csv</code>, and
          <code>outputs/tables/monthly_aggregates_by_state.csv</code>.
        </p>
      </section>
    </main>

    <footer>
      <p>Dataset-integrity analysis page. This report flags statistical signals and should be interpreted with domain and policy context.</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/d3@7"></script>
    <script src="https://cdn.jsdelivr.net/npm/topojson-client@3"></script>
    <script src="app.js?v=17"></script>
  </body>
</html>
