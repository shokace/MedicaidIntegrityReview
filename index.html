<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Medicaid Data Pattern Check</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Chivo:wght@400;700;900&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="styles.css?v=7" />
  </head>
  <body>
    <div class="noise"></div>
    <header class="hero">
      <p class="eyebrow">Medicaid Provider Spending, Jan 2018 - Dec 2024</p>
      <h1>Medicaid Data Pattern Check</h1>
      <p class="subtitle">
        This site checks whether a large Medicaid spending dataset looks natural. It does not accuse any person or organization of a crime.
        It looks for unusual patterns that can happen when data is edited, merged, rounded, or generated.
      </p>
      <div class="hero-grid">
        <div class="card stat">
          <span>Rows analyzed</span>
          <strong id="rowsAnalyzed">-</strong>
        </div>
        <div class="card stat">
          <span>Duplicate key rate</span>
          <strong id="dupRate">-</strong>
        </div>
      </div>
    </header>

    <main>
      <section class="panel" id="read-this-first">
        <h2>Read This First</h2>
        <p>
          We run six checks. Two of them measure the same behavior, so we treat them as one group.
          Real healthcare data is messy, so some fails are normal. We only raise a warning when
          <strong>3 or more independent groups fail</strong>.
        </p>
        <p>
          This is a <strong>screening tool</strong>. It helps you decide where to look closer. It is not legal proof,
          and it does not by itself prove fraud or abuse.
        </p>
      </section>

      <section class="panel" id="plain-language-definitions">
        <h2>Plain-Language Definitions</h2>
        <div class="grid-2">
          <div class="card prose-block">
            <h3>What is a "ratio"?</h3>
            <p>
              A ratio is one number divided by another. Here, an important one is <code>TOTAL_PAID / TOTAL_CLAIMS</code>,
              which is like payment per claim. If this swings too much in similar situations, something may be off.
            </p>
            <h3>What is "correlation"?</h3>
            <p>
              Correlation shows how strongly two things move together. It ranges from -1 to +1.
              In this dataset, some pairs should move together. If they do not, data structure may have changed.
            </p>
            <h3>What is "entropy"?</h3>
            <p>
              Entropy is a measure of variety. High entropy means values are spread out. Low entropy means too much repetition.
              Too much repetition can point to templated or overly processed data.
            </p>
          </div>
          <div class="card prose-block">
            <h3>What is "temporal noise"?</h3>
            <p>
              Temporal means over time. Real data usually has month-to-month bumps.
              If a long timeline looks too smooth, it may not reflect normal operations.
            </p>
            <h3>What is "heaping"?</h3>
            <p>
              Heaping means values bunch up at specific price steps (for example cents ending in 00, 25, 50, 75).
              Some heaping is normal in healthcare payments, but too much can be a warning sign.
            </p>
            <h3>What does "fail" mean here?</h3>
            <p>
              Fail means a metric crossed a cutoff that we treat as unusual. It does not mean guilt.
              It means that part of the data needs closer review.
            </p>
            <h3>Why healthcare can look irregular</h3>
            <p>
              Healthcare payment uses many rules (fee schedules, conversion formulas, contract grids, and shared patients across providers).
              Those rules can create strange-looking patterns even when data was not fabricated.
            </p>
          </div>
        </div>
      </section>

      <section class="panel" id="state-view">
        <h2>State Lens</h2>
        <p>
          National totals can hide local patterns. Pick a state to view the same checks for that state only.
          The cards, charts, tables, and verdict update automatically.
        </p>
        <div class="state-controls">
          <label for="stateSelect">Selected geography</label>
          <select id="stateSelect"></select>
          <p id="stateSelectionNote">Selected area: ALL</p>
        </div>
        <div id="usMap" class="us-map" aria-label="Interactive United States map"></div>
        <div class="card state-outliers-card">
          <h3>Provider Peer-Group Outlier Ranking</h3>
          <p id="peerOutlierSummary">
            Providers are ranked by how far they differ from peers in the selected area.
            This is a screening signal, not legal proof.
          </p>
          <div class="table-wrap table-wide">
            <table>
              <thead>
                <tr>
                  <th>Rank</th>
                  <th>Provider NPI</th>
                  <th>State</th>
                  <th>
                    <span class="info-label" data-help="Risk label based on how unusual this provider looks versus peers. HIGH: score >= 3.5 or far-from-normal share >= 0.40; ELEVATED: score >= 2.8 or share >= 0.25; WATCH: score >= 2.2 or share >= 0.15; otherwise LOW.">Risk <span class="info-dot">i</span></span>
                  </th>
                  <th>
                    <span class="info-label" data-help="One combined score showing how far this provider is from peer averages. Higher means more unusual.">How Unusual <span class="info-dot">i</span></span>
                  </th>
                  <th>
                    <span class="info-label" data-help="Share of checks that are very far from peers (3+ standard deviations, also called 3 sigma). Higher means more extreme differences.">Extreme Rows <span class="info-dot">i</span></span>
                  </th>
                  <th>
                    <span class="info-label" data-help="How many valid peer comparisons were available for this provider. More comparisons usually means a more stable score.">Peer Comparisons <span class="info-dot">i</span></span>
                  </th>
                  <th>
                    <span class="info-label" data-help="Total number of claims for this provider in the selected geography.">Total Claims <span class="info-dot">i</span></span>
                  </th>
                  <th>
                    <span class="info-label" data-help="Total paid amount for this provider in the selected geography.">Total Paid <span class="info-dot">i</span></span>
                  </th>
                </tr>
              </thead>
              <tbody id="peerOutlierTable"></tbody>
            </table>
          </div>
        </div>
      </section>

      <section class="panel" id="scorecard">
        <h2>Signal Scorecard (Ordered Workflow)</h2>
        <p>
          Quick pass/fail summary for all six signals. Full plain-language details are listed in the sections below.
        </p>
        <div class="card score-summary">
          <p><strong>Decision Rule:</strong> <span id="ruleText">-</span></p>
          <p><strong>Failed Independent Groups:</strong> <span id="failCount">-</span></p>
          <p><strong>Verdict:</strong> <span id="verdictText">-</span></p>
        </div>
        <div id="signalCards" class="signal-grid"></div>
      </section>

      <section class="panel" id="payment-mechanics">
        <h2>Signal 1 Detail: Payment-per-Claim Spread</h2>
        <p>
          We group data by procedure code and check how much payment per claim changes inside each group.
          If spread is very high in high-volume codes, the data may be mixing unlike patterns or may have been transformed in a problematic way.
        </p>
        <div class="card">
          <h3>Procedure Codes With Highest Instability</h3>
          <div class="table-wrap">
            <table>
              <thead><tr><th>Procedure Code</th><th>Claims</th><th>Spread</th><th>Alert Score</th></tr></thead>
              <tbody id="hcpcsTable"></tbody>
            </table>
          </div>
        </div>
        <div class="card" id="signal1Box">
          <h3>Signal 1 Result</h3>
          <p id="signal1Status">-</p>
          <p id="signal1Explain">-</p>
          <ul id="signal1Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="digit-forensics">
        <h2>Signal 2 Detail: Cents Pattern Check</h2>
        <p>
          We check the last cents digit (0-9) of implied payment per claim (<code>TOTAL_PAID / TOTAL_CLAIMS</code>).
          Too many values ending in just a few digits can be a warning sign.
        </p>
        <div class="card">
          <h3>Cents Last-Digit Distribution</h3>
          <canvas id="digitChart" width="920" height="280" aria-label="digit chart"></canvas>
        </div>
        <div class="card" id="signal2Box">
          <h3>Signal 2 Result</h3>
          <p id="signal2Status">-</p>
          <p id="signal2Explain">-</p>
          <ul id="signal2Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="relationships">
        <h2>Signal 3 Detail: Expected Relationships</h2>
        <p>
          Some fields should move together because they come from the same process.
          If those links are much weaker than expected, the data may have been altered or combined in inconsistent ways.
        </p>
        <div class="card">
          <h3>Core Correlations</h3>
          <div class="table-wrap">
            <table>
              <thead><tr><th>Pair</th><th>Correlation</th></tr></thead>
              <tbody id="corrTable"></tbody>
            </table>
          </div>
        </div>
        <div class="card" id="signal3Box">
          <h3>Signal 3 Result</h3>
          <p id="signal3Status">-</p>
          <p id="signal3Explain">-</p>
          <ul id="signal3Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="time-series">
        <h2>Signal 4 Detail: Month-to-Month Movement</h2>
        <p>
          We check month-to-month movement for “too smooth” behavior.
          Real systems usually have bumps, shocks, and seasonal swings.
        </p>
        <div class="card">
          <h3>Month-to-Month Change Size</h3>
          <canvas id="volChart" width="920" height="280" aria-label="month-to-month movement chart"></canvas>
        </div>
        <div class="card" id="signal4Box">
          <h3>Signal 4 Result</h3>
          <p id="signal4Status">-</p>
          <p id="signal4Explain">-</p>
          <ul id="signal4Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="entropy-detail">
        <h2>Signal 5 Detail: Repetition Check</h2>
        <p>
          Entropy measures variety in last-two-cent endings of implied payment values.
          If variety is too low, values may be repeating more than expected.
        </p>
        <div class="card" id="signal5Box">
          <h3>Signal 5 Result</h3>
          <p id="signal5Status">-</p>
          <p id="signal5Explain">-</p>
          <ul id="signal5Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="heaping-detail">
        <h2>Signal 6 Detail: Grid-Step Clustering</h2>
        <p>
          This checks whether payment cents cluster too strongly on price-grid steps.
          Some clustering is normal in healthcare pricing, but unusually strong clustering can be a warning sign.
        </p>
        <div class="card" id="signal6Box">
          <h3>Signal 6 Result</h3>
          <p id="signal6Status">-</p>
          <p id="signal6Explain">-</p>
          <ul id="signal6Metrics"></ul>
        </div>
      </section>

      <section class="panel" id="methodology">
        <h2>How To Read Results</h2>
        <ol>
          <li>We turn raw source files into analysis files for this page.</li>
          <li>We run six checks in a fixed order.</li>
          <li>Last-Digit and Repetition checks are counted together as one group because they test similar behavior.</li>
          <li>If 3 or more independent groups fail, we show a dataset-level warning.</li>
          <li>We interpret results with healthcare payment context in mind (not every unusual pattern means fraud).</li>
          <li>This is a screening tool to prioritize review, not legal proof.</li>
        </ol>
      </section>

      <section class="panel" id="payer-mechanics">
        <h2>Why Some Weird Patterns Are Normal</h2>
        <p>
          In healthcare data, unusual patterns can come from payment rules, not fabrication. Keep these in mind when reading failed signals:
        </p>
        <div class="grid-2">
          <div class="card prose-block">
            <h3>CPT/HCPCS Fee Schedules</h3>
            <p>
              Many services are paid using fixed code-based schedules, which can naturally create repeated payment patterns.
            </p>
            <h3>RVU Conversion Factors</h3>
            <p>
              Payment formulas can shift many values at once when policy settings change.
            </p>
          </div>
          <div class="card prose-block">
            <h3>Negotiated Reimbursement Grids</h3>
            <p>
              Contract rates often use step-like grids, which can create clustering that is operational and expected.
            </p>
            <h3>Shared Beneficiaries Across Providers</h3>
            <p>
              The same patient can appear across many providers and services, which can blur simple relationships in rolled-up data.
            </p>
          </div>
        </div>
      </section>

      <section class="panel" id="data-health">
        <h2>Data Quality Check</h2>
        <p>
          Before looking for unusual patterns, we check that basic data quality looks reasonable.
          If basic quality is poor, later conclusions can be misleading.
        </p>
        <div class="grid-2">
          <div class="card">
            <h3>Integrity Checks</h3>
            <ul id="healthChecks"></ul>
          </div>
          <div class="card">
            <h3>Missingness by Column</h3>
            <div class="table-wrap">
              <table>
                <thead><tr><th>Column</th><th>Missing %</th></tr></thead>
                <tbody id="missingnessTable"></tbody>
              </table>
            </div>
          </div>
        </div>
      </section>

      <section class="panel" id="appendix">
        <h2>Data Files Used</h2>
        <p>
          Main data files loaded by this page:
          <code>outputs/json/report_by_state.json</code>,
          <code>outputs/json/signal_score_by_state.json</code>,
          <code>outputs/json/provider_peer_outliers_by_state.json</code>,
          with fallback to <code>outputs/json/report.json</code> and <code>outputs/json/signal_score.json</code>,
          <code>outputs/tables/unit_price_top_suspicious_hcpcs.csv</code>, and
          <code>outputs/tables/monthly_aggregates_by_state.csv</code>.
        </p>
      </section>
    </main>

    <footer>
      <p>
        This page flags unusual patterns. Use it to guide deeper review, not as final proof on its own.
        Full project details: <a href="https://github.com/shokace/MedicaidIntegrityReview" target="_blank" rel="noopener noreferrer">github.com/shokace/MedicaidIntegrityReview</a>.
      </p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/d3@7"></script>
    <script src="https://cdn.jsdelivr.net/npm/topojson-client@3"></script>
    <script src="app.js?v=20"></script>
  </body>
</html>
